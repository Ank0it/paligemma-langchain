{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d775fbf",
   "metadata": {},
   "source": [
    "Using Paligemma with transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce0fcb",
   "metadata": {},
   "source": [
    "Paligemma is a new vision language model released by Google.In this notebook we will see how to use transformer for Paligemma interface.First, install below libraries with update flag as we need to use the latest version of transformers along with others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "551b4a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U accelerate bitsandbytes git+https://github.com/huggingface/transformers.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0a3cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cbe3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "input_text=\"What is the color of bee standing on the flower?\"\n",
    "img_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/bee.JPG?download=true\"\n",
    "imput_image = Image.open(requests.get(img_url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aaa6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"google/paligemma-3b-pt-224\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\"google/paligemma-3b-pt-224\")\n",
    "from transformers import AutoTokenizer, PaliGemmaForConditionalGeneration, PaliGemmaProcessor\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_id = \"google/paligemma-3b-mix-224\"\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.bfloat16)\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(text=input_text, images=input_image,\n",
    "                  padding=\"longest\", do_convert_rgb=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "model.to(device)\n",
    "inputs = inputs.to(dtype=model.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  output = model.generate(**inputs, max_length=496)\n",
    "\n",
    "print(processor.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e7be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd31230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, PaliGemmaForConditionalGeneration, PaliGemmaProcessor\n",
    "import torch\n",
    "\n",
    "device=\"cuda\"\n",
    "model_id = \"google/paligemma-3b-mix-224\"\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.bfloat16,\n",
    "                                                          quantization_config=nf4_config, device_map={\"\":0})\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9929ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  output = model.generate(**inputs, max_length=496)\n",
    "\n",
    "print(processor.decode(output[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
